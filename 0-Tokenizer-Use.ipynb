{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from importlib.metadata import version\n","import tiktoken\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","print(\"tiktoken version:\", version(\"tiktoken\"))\n","\n","sample_tentence = \"This is a beautiful day! <|endoftext|> Will it be raining?\"\n","\n","ids = tokenizer.encode(sample_tentence, allowed_special={\"<|endoftext|>\"})\n","\n","print(ids)\n","\n","words = tokenizer.decode(ids)\n","\n","print(words)\n","\n","# 50256 id - <|endoftext|> token.\n","# Breaks down unknow words into known tokens.\n","# Merges frequent characters into characters. Frequent subwords into words.\n","\n","sample_sentence_2 = \"Break. This. Down. BAr. gwhm.\"\n","ids_2 = tokenizer.encode(sample_sentence_2)\n","print(ids_2)"]},{"cell_type":"markdown","metadata":{},"source":["\n","Data Sampling with sliding window\n","#https://www.gutenberg.org/cache/epub/74/pg74.txt\n","# The Adventures of Tom Sawyer by Mark Twain"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"pg74.txt\", \"r\", encoding=\"utf-8\") as file:\n","    text = file.read()\n","    \n","encoded_text = tokenizer.encode(text)\n","print(len(text))"]},{"cell_type":"markdown","metadata":{},"source":["Training dataset: outputs are inputs shifted by 1:\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_size = 4\n","encoded_sample = encoded_text[100:]\n","x = encoded_sample[:context_size]\n","y = encoded_sample[1:context_size+1]\n","print(f\"x: {x}\")\n","print(f\"y: {y}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(1, context_size+1):\n","    context = encoded_sample[:i]\n","    target = encoded_sample[i]\n","    print(context, \"---->\", target)\n","    \n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class LLMDataset(Dataset):\n","    def __init__(self, text, seq_length, step):\n","        self.tokenizer = tiktoken.get_encoding(\"gpt2\")\n","        self.ids = self.tokenizer.encode(text)\n","        self.x = []\n","        self.y = []\n","        \n","        for i in range(0, len(self.ids) - seq_length, step):\n","            x_i = self.ids[i : i + seq_length]\n","            y_i = self.ids[i+step : i + seq_length + step]\n","            self.x.append(torch.tensor(x_i))\n","            self.y.append(torch.tensor(y_i))\n","            \n","    def __len__(self):\n","        return len(self.x)\n","    \n","    def __getitem__(self, i):\n","        if i >= len(self.x) or i >= len(self.y):\n","            raise IndentationError(f\"Index {i} is out of range\")\n","        return self.x[i], self.y[i]\n","    \n","llm_dataset = LLMDataset(text, seq_length=4, step=4)\n","\n","print(len(llm_dataset))\n","print(llm_dataset[100])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataloader = DataLoader(llm_dataset, batch_size=8, shuffle=False, drop_last=True, num_workers=0)\n","#common length for LLMs is 256\n","data_iterator = iter(dataloader)\n","print(data_iterator)\n","x1, y1 = next(data_iterator)\n","print(x1, y1)\n","x2, y2 = next(data_iterator)\n","print(x2, y2)"]},{"cell_type":"markdown","metadata":{},"source":["Token Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.manual_seed(0)\n","embedding_layer = torch.nn.Embedding(num_embeddings=10, embedding_dim=4)\n","print(embedding_layer.weight)\n","#Will be optimized during training\n","print(embedding_layer(torch.tensor([2])))\n","#Embedding layer retrieves rows from embedding layers weight matrix by token id\n"]},{"cell_type":"markdown","metadata":{},"source":["Encoding word positions - \n","absolute positional embeddings encode exact position in a sequence (GPT). In the original Transformer model they were predefined (fixed).\n","relative positional embeddings encode how far apart tokens (relative positions) are versus their exact position in a sequence\n","optimized during the training process.\n","\n","Initial postional embeddings:\n","(Original GPT3 model 12288 dim)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embedding_dimensions = 256\n","embedding_layer = torch.nn.Embedding(num_embeddings=50257, embedding_dim=embedding_dimensions)\n","print(\"Token IDs\", x1)\n","print(\"Shape\", x1.shape)\n","#Tensor size: batch_size x sequence_length x embedding_dim -> 8*4*256 tensor\n","x1_embeddings = embedding_layer(x1)\n","print(x1_embeddings.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Absolute embeddings\n","# Context length: (input text can be longer than context length)\n","sequence_length = 4\n","context_length = sequence_length\n","position_embedding_layer = torch.nn.Embedding(context_length, embedding_dimensions)\n","position_embeddings = position_embedding_layer(torch.arange(sequence_length))\n","print(position_embeddings.shape)\n","full_embeddings = x1_embeddings + position_embeddings\n","print(full_embeddings.shape)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
